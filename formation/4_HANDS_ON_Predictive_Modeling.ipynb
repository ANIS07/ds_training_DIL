{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning <font color='blue'> (35 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google doc with code corrections is accessible at:\n",
    "### https://docs.google.com/document/d/1phmpGjNJbHwxP7448taFqREw6Vw3qVSUEDhu1KcLxog/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Importing the right tools <font color='blue'> (5 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>0.1) Import the necessary packages with their usual aliases: </font>\n",
    "\n",
    "- pandas as pd\n",
    "- numpy as np\n",
    "- seaborn as sns\n",
    "- matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "#### IMPORT THE USUAL PACKAGES WITH THEIR ALIASES ####\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>0.2) Import the dataset from <i>'../data/data_after_feature_engineering.csv'</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = #### IMPORT AND READ THE CSV DATA USING pd.read_csv() #### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>0.3) Copy the raw_data and print samples</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = #### COPY THE RAW DATA WITH THE .copy() FUNCTION ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PRINT SAMPLES USING .sample() AND CHECK THE FEATURES ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Variable encoding <font color='blue'> (10 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables need to be converted to numbers so as to train machine learning algorithms. There are different kinds of variables encoding, such as dummy-encoding: this method consists in building $n$ binary columns when a variable can take $n$ values. When regression is used, features need not be correlated, hence $n-1$ binary columns will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>1.1) Understand how the <i>pd.get_dummies(data.column_name_here)</i> function allows to create dummy variables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TRY HERE TO DUMMY-ENCODE WEATHER CONDITIONS OF THE DATASET, USING pd.get_dummies(data.Conditions) ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>1.2) Print the names of the columns of the dataset using <i>data.columns</i>. Which ones should be dummified ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PRINT THE NAMES OF THE COLUMNS ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>1.3) Fill in the following loop so you append to the existing DataFrame the newly created dummy columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for variable_name in ['Conditions','start_day','is_weekend',\n",
    "                      'start_moment','is_rainy','is_circle_trip']:\n",
    "    print 'Dummifying the {} variable ...'.format(variable_name)\n",
    "    \n",
    "    dummies = #### CREATE DUMMIES FROM THE COLUMN data[variable_name], as you did above with pd.get_dummies() ####\n",
    "    \n",
    "    dummies.columns = ['{}_{}'.format(variable_name,x) for x in dummies.columns]  # this will rename the column\n",
    "                                                                                  # in an appropriate way\n",
    "        \n",
    "    data = pd.concat([data,dummies],axis=1)  # This will append the dummy column to the existing dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>1.4) Once you are sure that the dummy columns have been created (check by printing samples), delete the old columns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CHECK THAT DUMMIFICATION IS SUCCESSFUL BY PRINTING SAMPLES AND COLUMNS NAMES ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for variable_name in ['Conditions','start_day','is_weekend',\n",
    "                      'start_moment','is_rainy','is_circle_trip']:\n",
    "    print 'Deleting the {} variable ...'.format(variable_name)\n",
    "    #### DELETE THE OLD COLUMN USING del data[column_name_here] HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Correlation matrix <font color='blue'> (10 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>2.1) Using the <i>.corr()</i> method on <i>data</i>, print samples of the Pearson correlations between features within the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = #### COMPUTE THE PEARSON CORRELATION BETWEEN FEATURES HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PRINT SAMPLES OF THE CORRELATIONS HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>2.2) Using the <i>sns.heatmap()</i> function of seaborn, plot the Pearson correlations between features. You can refer to https://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.heatmap.html to add a mask and make the plot look better</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cross-validation : trying to predict customer vs. subscriber <font color='blue'> (30 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.1) Use the <i>seaborn</i> function <i>sns.countplot(data.column_name_here)</i> to countplot the repartition of trips per user type (i.e the <i>usertype</i> column)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### COUNTPLOT THE REPARTITION OF TRIPS PER USER TYPE AND ADD A CLEAR TITLE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Run the following block, it will delete a few columns for predictive modeling purposes </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['starttime'], data['stoptime'], data['start station name'], data['end station name']\n",
    "del data['gender'], data['birth year']\n",
    "del data['bikeid']\n",
    "del data['start station id'], data['end station id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.2) Print the different columns using <i>data.columns</i> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PRINT THE COLUMNS OF THE DATASET ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.3) Run the following block. It builds arrays for the features, as well as the labels. Features will be used to predict the labels. Study their structures.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(data.usertype)\n",
    "del data['usertype']\n",
    "features = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Study the structure of features and labels ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.4) How many observations/features do we have to make our models ? You can use the <i>.shape</i> attribute of features, and labels</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.5) Import the scikit-learn package (called <i>sklearn</i>), that will be used for running machine learning algorithms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### IMPORT THE SCIKIT-LEARN PACKAGE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.6) Binarize the labels of the dataset. You can use the following webpage:</font>\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.label_binarize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "binarized_labels = #### BINARIZE THE LABELS OF THE DATASET, AND RAVEL THE RESULT USING .ravel() ####\n",
    "                   #### Subscriber will be label 1, Customer label 0 ####\n",
    "                   #### This will be a binary classifiation problem ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.7) Show the binarized labels</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.8) Split your dataset between a training and testing set (of size 30%). You can use the following webpage:</font>\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = #### SPLIT BETWEEN TRAIN AND TEST ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.9) Show the results of your split</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Show samples of X_train, X_test, y_train, y_test ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.10) Go to the following webpages to understand how to compute cross-validation scores of a Random Forest classifier in Python, on the training set:</font>\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = #### DEFINE A RANDOM FOREST CLASSIFIER ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Run the following block. It will compute a 3-fold cross-validation score using the </font><b>AUC scoring metric</b>,  <font color='red'>as explained in the slides</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(rf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>3.11) Take some time to run as well as understand the following block. \n",
    "\n",
    "<b>This does exactly as <i>cross_val_score</i> function from the block above, but it is coded such that you will understand what happens at each iteration, as well as plot the ROC curve for every cross-validation split</b>. You can use the following webpages:</font>\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(y_train, n_folds=3)\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "mean_tpr = 0.\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_tpr = []\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for i, (train, test) in enumerate(cv,1):\n",
    "    print 'Fold {}'.format(i)\n",
    "    probas_ = classifier.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "    # Compute ROC curve and area under the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1], pos_label=1)\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "\n",
    "mean_tpr /= len(cv)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for Random Forest Classifier',fontsize=17)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Final fit and plots <font color='blue'> (15 min) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.1) Define a random forest classifier, and fit it on the training set. You can return on:</font>\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = #### DEFINE A RANDOM FOREST CLASSIFIER ####\n",
    "\n",
    "#### FIT THE RANDOM FOREST CLASSIFIER ON THE TRAINING SET ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.2) Show (and if you can, plot!) the features importances using the <i>.feature_importances</i> attribute of your classifier. You can get hints on the following page:</font>\n",
    "- http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PLOT THE FEATURES IMPORTANCES WITH RESPECT TO THE RANDOM FOREST ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.3) Run this block to get the final performance on test set, using <i>roc_auc_score</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final AUC score on test set : 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_predict_test = rf.predict_proba(X_test)[:,1]\n",
    "print 'Final AUC score on test set : {:.2f}'.format(roc_auc_score(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.4) Using <i>seaborn.distplot</i>, plot the distribution of trip durations with respect to user type (whether \"Subscriber\" or \"Customer\")</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PLOT THE DISTRIBUTION OF TRIP DURATIONS WITH RESPECT TO USER TYPES BY USING APPROPRIATE SLICES ON RAW_DATA ####\n",
    "\n",
    "#### ADD X,Y LABELS, A TITLE, AND A LEGEND TO THIS PLOT ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.5) Using <i>seaborn.distplot</i>, plot the distribution of average speed with respect to user type (whether \"Subscriber\" or \"Customer\")</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### PLOT THE DISTRIBUTION OF AVERAGE SPEEDS WITH RESPECT TO USER TYPES BY USING APPROPRIATE SLICES ON RAW_DATA ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>4.6) Run the following block to understand how fine-tuning parameters can help improve the performance of your models. Warning : this will take some time to run !</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=20,max_features=10,n_estimators=50)\n",
    "cross_val_score(rf, X_train, y_train, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free exploration/modeling of the dataset, for instance: <font color='blue'> (45 min) </font>\n",
    "- Try to use other algorithms\n",
    "- Try to enrich with other data (taxi trips, points of interests in neighborhoods)\n",
    "- Try to predict other phenomena\n",
    "- ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please give us your feedback on the hands-on sessions at:\n",
    "## <center>https://docs.google.com/forms/d/e/1FAIpQLScw_fPB1m6x_sMm59v_VHNBVcvfsMPhoqXwSjSiJQtzlpOJJA/viewform?usp=sf_link</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
